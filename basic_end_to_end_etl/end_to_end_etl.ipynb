{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a basic end to end Extract Transform and Load(ETL) pipeline using spark and postgres\n",
    "### Data is scrapped from Stack overflow into the following tables:\n",
    "- Questions\n",
    "- Answers\n",
    "- Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract stage:\n",
    "\n",
    "using pyspark \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gi-pc6/de/basic_etl/venv/lib/python2.7/site-packages/pyspark/context.py:220: DeprecationWarning: Support for Python 2 and Python 3 prior to version 3.6 is deprecated as of Spark 3.0. See also the plan for dropping Python 2 support at https://spark.apache.org/news/plan-for-dropping-python-2-support.html.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# creating a spark session\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "                     .appName(\"Stack Overflow Data Wrangling\")\n",
    "                     .config(\"spark.jars\",\"jars/postgresql-42.2.14.jar\")#this should aid with database connection\n",
    "                     .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = spark.read.csv('../data/stackoverflow/users.csv', inferSchema=True, header=True, escape='\"',multiLine=True)\n",
    "questions_df = spark.read.csv('../data/stackoverflow/questions.csv',inferSchema=True, header=True, escape= '\"', multiLine=True)\n",
    "answers_df = spark.read.csv('../data/stackoverflow/answers.csv',inferSchema=True, header=True, escape= '\"', multiLine=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transform Stage:\n",
    "\n",
    "- Step 1: Select users from one country only\n",
    "- Step 2: Extract the country and city into new columns.\n",
    "- Step 3: Join the result with the questions and select only questions with at least 20 view counts\n",
    "- Step 4: Join the answers to the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- display_name: string (nullable = true)\n",
      " |-- reputation: integer (nullable = true)\n",
      " |-- website_url: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- about_me: string (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      " |-- up_votes: integer (nullable = true)\n",
      " |-- down_votes: integer (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- updated_at: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243028"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the id column because of a join.. later on\n",
    "users_df = users_df.withColumnRenamed(\"id\",\"user_id\")\\\n",
    "                   .withColumnRenamed(\"created_at\",\"user_created_at\")\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 'display_name',\n",
       " 'reputation',\n",
       " 'website_url',\n",
       " 'location',\n",
       " 'about_me',\n",
       " 'views',\n",
       " 'up_votes',\n",
       " 'down_votes',\n",
       " 'image_url',\n",
       " 'user_created_at',\n",
       " 'updated_at']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            location|\n",
      "+--------------------+\n",
      "|Bangalore, Karnat...|\n",
      "|              Canada|\n",
      "|Pennsylvania, Uni...|\n",
      "|                null|\n",
      "|New Delhi, Delhi,...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df[['location']].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Select users from one country only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering in spark is soooooo cooooooool\n",
    "india_users = users_df.filter(users_df.location.contains('India'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21754"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_users.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Extract the country and city into new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the location to extract the City value...\n",
    "india_users_city_added = india_users.withColumn(\"City\", F.split(india_users.location, ',')[0].alias(\"City\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+----------+--------------------+--------------------+--------+-----+--------+----------+--------------------+-------------------+-------------------+---------+\n",
      "|user_id|display_name|reputation|         website_url|            location|about_me|views|up_votes|down_votes|           image_url|    user_created_at|         updated_at|     City|\n",
      "+-------+------------+----------+--------------------+--------------------+--------+-----+--------+----------+--------------------+-------------------+-------------------+---------+\n",
      "|8357266|      suryan|         7|https://twitter.c...|Bangalore, Karnat...|    null|    8|       0|         0|https://www.grava...|2017-07-24 10:55:23|2019-06-19 05:00:16|Bangalore|\n",
      "|6504306|       A.Raw|         4|                null|New Delhi, Delhi,...|    null|   10|       0|         0|https://i.stack.i...|2016-06-23 12:58:03|2019-10-12 06:59:32|New Delhi|\n",
      "+-------+------------+----------+--------------------+--------------------+--------+-----+--------+----------+--------------------+-------------------+-------------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "india_users_city_added.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the same thing to get the Column value.\n",
    "# ok so after splitting the [-1] wasn't working to get the last index so i had to reverse the list before accessing the first value which would be the last in this case \n",
    "\n",
    "india_users_country_added = india_users_city_added.withColumn(\"Country\",F.reverse(F.split(india_users_city_added.location, ','))[0].alias(\"Country\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+----------+--------------------+--------------------+--------+-----+--------+----------+--------------------+-------------------+-------------------+---------+-------+\n",
      "|user_id|display_name|reputation|         website_url|            location|about_me|views|up_votes|down_votes|           image_url|    user_created_at|         updated_at|     City|Country|\n",
      "+-------+------------+----------+--------------------+--------------------+--------+-----+--------+----------+--------------------+-------------------+-------------------+---------+-------+\n",
      "|8357266|      suryan|         7|https://twitter.c...|Bangalore, Karnat...|    null|    8|       0|         0|https://www.grava...|2017-07-24 10:55:23|2019-06-19 05:00:16|Bangalore|  India|\n",
      "|6504306|       A.Raw|         4|                null|New Delhi, Delhi,...|    null|   10|       0|         0|https://i.stack.i...|2016-06-23 12:58:03|2019-10-12 06:59:32|New Delhi|  India|\n",
      "+-------+------------+----------+--------------------+--------------------+--------+-----+--------+----------+--------------------+-------------------+-------------------+---------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "india_users_country_added.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            location|     City|Country|\n",
      "+--------------------+---------+-------+\n",
      "|Bangalore, Karnat...|Bangalore|  India|\n",
      "|New Delhi, Delhi,...|New Delhi|  India|\n",
      "|Gharaunda, Haryan...|Gharaunda|  India|\n",
      "|    New Delhi, India|New Delhi|  India|\n",
      "|Jalandhar, Punjab...|Jalandhar|  India|\n",
      "+--------------------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "india_users_country_added.select('location','City','Country').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 'display_name',\n",
       " 'reputation',\n",
       " 'website_url',\n",
       " 'location',\n",
       " 'about_me',\n",
       " 'views',\n",
       " 'up_votes',\n",
       " 'down_votes',\n",
       " 'image_url',\n",
       " 'user_created_at',\n",
       " 'updated_at',\n",
       " 'City',\n",
       " 'Country']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_users_country_added.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21754"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_users_country_added.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Join the result with the questions and select only questions with at least 20 view counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- accepted_answer_id: integer (nullable = true)\n",
      " |-- score: integer (nullable = true)\n",
      " |-- view_count: integer (nullable = true)\n",
      " |-- comment_count: integer (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df= questions_df.withColumnRenamed(\"id\",\"question_id\")\\\n",
    "                            .withColumnRenamed(\"created_at\",\"question_created_at\")\\\n",
    "                            .withColumnRenamed(\"comment_count\",\"question_comment_count\")\\\n",
    "                            .withColumnRenamed(\"score\",\"question_score\")\\\n",
    "                            .withColumnRenamed(\"body\",\"question_body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_users_df = questions_df.join(india_users_country_added, on=['user_id'],how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- question_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- question_body: string (nullable = true)\n",
      " |-- accepted_answer_id: integer (nullable = true)\n",
      " |-- question_score: integer (nullable = true)\n",
      " |-- view_count: integer (nullable = true)\n",
      " |-- question_comment_count: integer (nullable = true)\n",
      " |-- question_created_at: string (nullable = true)\n",
      " |-- display_name: string (nullable = true)\n",
      " |-- reputation: integer (nullable = true)\n",
      " |-- website_url: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- about_me: string (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      " |-- up_votes: integer (nullable = true)\n",
      " |-- down_votes: integer (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- user_created_at: string (nullable = true)\n",
      " |-- updated_at: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions_users_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_at_least_20_views = questions_users_df.filter(questions_users_df['view_count'] > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Join the answers to the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- question_id: integer (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- score: integer (nullable = true)\n",
      " |-- comment_count: integer (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answers_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming for the sake of the joining....\n",
    "answers_df= answers_df.withColumnRenamed(\"id\",\"answer_id\")\\\n",
    "                        .withColumnRenamed(\"score\",\"answer_score\")\\\n",
    "                        .withColumnRenamed(\"comment_count\",\"answer_comment_count\")\\\n",
    "                        .withColumnRenamed(\"created_at\",\"answer_created_at\")\\\n",
    "                        .withColumnRenamed(\"body\",\"answer_body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_added = answers_df.join(questions_at_least_20_views, on=['question_id', 'user_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2411"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_added.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- question_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- answer_id: integer (nullable = true)\n",
      " |-- answer_body: string (nullable = true)\n",
      " |-- answer_score: integer (nullable = true)\n",
      " |-- answer_comment_count: integer (nullable = true)\n",
      " |-- answer_created_at: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- question_body: string (nullable = true)\n",
      " |-- accepted_answer_id: integer (nullable = true)\n",
      " |-- question_score: integer (nullable = true)\n",
      " |-- view_count: integer (nullable = true)\n",
      " |-- question_comment_count: integer (nullable = true)\n",
      " |-- question_created_at: string (nullable = true)\n",
      " |-- display_name: string (nullable = true)\n",
      " |-- reputation: integer (nullable = true)\n",
      " |-- website_url: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- about_me: string (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      " |-- up_votes: integer (nullable = true)\n",
      " |-- down_votes: integer (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- user_created_at: string (nullable = true)\n",
      " |-- updated_at: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answers_added.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = answers_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|minimum_updated_time|\n",
      "+--------------------+\n",
      "| 2019-01-11 05:02:30|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answers_added.registerTempTable('new_df')\n",
    "spark.sql(\"Select min(updated_at) as minimum_updated_time from new_df\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Definition part\n",
    "\n",
    "Using SQL\n",
    "- Creating a schema based on the resultant dataframe\n",
    "- Create a table called results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading part\n",
    "\n",
    "- using spark write the resultant dataframe to the table created in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.write.format(\"jdbc\").options(\n",
    "    url='jdbc:postgresql://localhost:5432/postgres',\n",
    "    driver='org.postgresql.Driver',\n",
    "    user='postgres',\n",
    "    password='pass',\n",
    "    dbtable='stackoverflow_filtered.results'\n",
    ").save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok so what if i want to ge the length of each array in the splitted column appended to this as a new column\n",
    "# the pseudocode im looking at is\n",
    "# if the length of the array is 2 the first index is the city and the other is the country\n",
    "# if the length is 1 then that's the country\n",
    "# for others i don't know yet....\n",
    "\n",
    "# ok a rewrite split the location column\n",
    "# assume the first index is the city and the last index is the country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243028"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok so filtering based on the condition that the length column is greater than 3\n",
    "filtered_df = df.where(F.size(F.col(\"splitted\")) >= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok so now \n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88554"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to a csv\n",
    "result.toPandas().to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----------+-----------+--------+--------+-----+--------+----------+---------+----------+----------+----+-------+\n",
      "| id|display_name|reputation|website_url|location|about_me|views|up_votes|down_votes|image_url|created_at|updated_at|City|Country|\n",
      "+---+------------+----------+-----------+--------+--------+-----+--------+----------+---------+----------+----------+----+-------+\n",
      "|  0|           0|         0|      17654|       0|   11683|    0|       0|         0|     1936|         0|         0|   0|      0|\n",
      "+---+------------+----------+-----------+--------+--------+-----+--------+----------+---------+----------+----------+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ok i'm saving this code till i fully understand how it works  :)))))))\n",
    "\n",
    "india_users_country_added.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in india_users_country_added.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}