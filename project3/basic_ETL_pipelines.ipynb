{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Extract Transform and Load(ETL) pipeline using spark and postgres\n",
    "### Data is scrapped from Stack overflow into the following tables:\n",
    "- Questions\n",
    "- Answers\n",
    "- Users\n",
    "\n",
    "#### This script is divided into 4 steps to illustrate the process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing spark a spark session\n",
    "spark = ( \n",
    "    SparkSession.builder\n",
    "                .appName(\"Stack Overflow Data Wrangling\")\n",
    "                .config(\"spark.jars\", \"../jars/postgresql-42.2.8.jar\")\n",
    "                .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data in dataframes\n",
    "answers = spark.read.csv(\"../data/stackoverflow/answers.csv\", header=True, multiLine=True, inferSchema=True)\n",
    "questions = spark.read.csv(\"../data/stackoverflow/questions.csv\", header=True, inferSchema=True,multiLine=True)\n",
    "users = spark.read.csv(\"../data/stackoverflow/users.csv\", header=True, inferSchema=True,multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'user_id',\n",
       " 'question_id',\n",
       " 'body',\n",
       " 'score',\n",
       " 'comment_count',\n",
       " 'created_at']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'display_name',\n",
       " 'reputation',\n",
       " 'website_url',\n",
       " 'location',\n",
       " 'about_me',\n",
       " 'views',\n",
       " 'up_votes',\n",
       " 'down_votes',\n",
       " 'image_url',\n",
       " 'created_at',\n",
       " 'updated_at']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'user_id',\n",
       " 'title',\n",
       " 'body',\n",
       " 'accepted_answer_id',\n",
       " 'score',\n",
       " 'view_count',\n",
       " 'comment_count',\n",
       " 'created_at']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the id column names as well as the timestamps too to avoid the ambiguity\n",
    "answers = answers.withColumnRenamed('id', 'answer_id').withColumnRenamed('created_at', 'answer_created_at').withColumnRenamed('body','answer_body').withColumnRenamed('score','answer_score').withColumnRenamed('comment_count','answer_comment_count')\n",
    "questions = questions.withColumnRenamed('id', 'question_id').withColumnRenamed('created_at', 'question_created_at').withColumnRenamed('body','question_body').withColumnRenamed('score','question_score')\n",
    "users = users.withColumnRenamed('id', 'user_id').withColumnRenamed('created_at', 'user_created_at').withColumnRenamed('updated_at', 'user_updated_at')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting only indian users..\n",
    "india_users = users.filter(users.location.contains('India'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            location|\n",
      "+--------------------+\n",
      "|Bangalore, Karnat...|\n",
      "|New Delhi, Delhi,...|\n",
      "|Gharaunda, Haryan...|\n",
      "|    New Delhi, India|\n",
      "|Jalandhar, Punjab...|\n",
      "|Surat, Gujarat, I...|\n",
      "|Darjeeling, West ...|\n",
      "|Pune, Maharashtra...|\n",
      "|Mumbai, Maharasht...|\n",
      "|Bangalore, Karnat...|\n",
      "|Mumbai, Maharasht...|\n",
      "|Bangalore, Karnat...|\n",
      "|Mumbai, Maharasht...|\n",
      "|Hyderabad, Telang...|\n",
      "|Indore, Madhya Pr...|\n",
      "|               India|\n",
      "|Bangalore, Karnat...|\n",
      "|Naya Raipur, Chha...|\n",
      "|Bangalore, Karnat...|\n",
      "|Chennai, Tamil Na...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "india_users.select(\"location\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the country and city into new columns\n",
    "cols = F.split(india_users['location'], ',' )\n",
    "india_users = india_users.withColumn('city', cols.getItem(0))\n",
    "india_users = india_users.withColumn('country', cols.getItem(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------+\n",
      "|            location|       city|country|\n",
      "+--------------------+-----------+-------+\n",
      "|Bangalore, Karnat...|  Bangalore|  India|\n",
      "|New Delhi, Delhi,...|  New Delhi|  India|\n",
      "|Gharaunda, Haryan...|  Gharaunda|  India|\n",
      "|    New Delhi, India|  New Delhi|   null|\n",
      "|Jalandhar, Punjab...|  Jalandhar|  India|\n",
      "|Surat, Gujarat, I...|      Surat|  India|\n",
      "|Darjeeling, West ...| Darjeeling|  India|\n",
      "|Pune, Maharashtra...|       Pune|  India|\n",
      "|Mumbai, Maharasht...|     Mumbai|  India|\n",
      "|Bangalore, Karnat...|  Bangalore|  India|\n",
      "|Mumbai, Maharasht...|     Mumbai|  India|\n",
      "|Bangalore, Karnat...|  Bangalore|  India|\n",
      "|Mumbai, Maharasht...|     Mumbai|  India|\n",
      "|Hyderabad, Telang...|  Hyderabad|  India|\n",
      "|Indore, Madhya Pr...|     Indore|  India|\n",
      "|               India|      India|   null|\n",
      "|Bangalore, Karnat...|  Bangalore|  India|\n",
      "|Naya Raipur, Chha...|Naya Raipur|  India|\n",
      "|Bangalore, Karnat...|  Bangalore|  India|\n",
      "|Chennai, Tamil Na...|    Chennai|  India|\n",
      "+--------------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rows where city was not quoted the country are being taken as None\n",
    "india_users.select(['location','city','country']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 'display_name',\n",
       " 'reputation',\n",
       " 'website_url',\n",
       " 'location',\n",
       " 'about_me',\n",
       " 'views',\n",
       " 'up_votes',\n",
       " 'down_votes',\n",
       " 'image_url',\n",
       " 'user_created_at',\n",
       " 'user_updated_at',\n",
       " 'city',\n",
       " 'country',\n",
       " 'question_id',\n",
       " 'title',\n",
       " 'question_body',\n",
       " 'accepted_answer_id',\n",
       " 'question_score',\n",
       " 'view_count',\n",
       " 'comment_count',\n",
       " 'question_created_at']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an inner join of the filtered users df with the question df\n",
    "df = india_users.join(questions, on='user_id', how='left')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only questions with at least 20 view counts\n",
    "df = df.filter(df['view_count'] >= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question_id',\n",
       " 'user_id',\n",
       " 'display_name',\n",
       " 'reputation',\n",
       " 'website_url',\n",
       " 'location',\n",
       " 'about_me',\n",
       " 'views',\n",
       " 'up_votes',\n",
       " 'down_votes',\n",
       " 'image_url',\n",
       " 'user_created_at',\n",
       " 'user_updated_at',\n",
       " 'city',\n",
       " 'country',\n",
       " 'title',\n",
       " 'question_body',\n",
       " 'accepted_answer_id',\n",
       " 'question_score',\n",
       " 'view_count',\n",
       " 'comment_count',\n",
       " 'question_created_at',\n",
       " 'answer_id',\n",
       " 'answer_body',\n",
       " 'answer_score',\n",
       " 'answer_comment_count',\n",
       " 'answer_created_at']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joining the resultant table to the users answers table\n",
    "df = df.join(answers, on=['question_id','user_id'], how='left')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to the a postgres database\n",
    "# assuming the schema is already created.\n",
    "df.write.format(\"jdbc\").options(\n",
    "    url='jdbc:postgresql://localhost:5432/postgres',\n",
    "    driver='org.postgresql.Driver',\n",
    "    user='postgres',\n",
    "    password='postgres',\n",
    "    dbtable='stackoverflow_filtered.results'\n",
    ").save(mode='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences bewteen a view and a materialised view.\n",
    "- A view is never stored it is only displayed a materialised view is stored on the disk\n",
    "- A view is a virtual table but a materialized view is a physical copy of a table\n",
    "- A view is updated anytime is used but a materialised view has to be updated manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
